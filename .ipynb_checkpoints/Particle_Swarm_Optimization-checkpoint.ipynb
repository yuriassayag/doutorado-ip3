{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb1e4ba",
   "metadata": {
    "id": "0eb1e4ba"
   },
   "source": [
    "### Imports e Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6089fa",
   "metadata": {
    "id": "cd6089fa"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib         import pyplot as plt\n",
    "#from pyswarm            import pso\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from time import sleep, time\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb143787",
   "metadata": {
    "id": "cb143787"
   },
   "outputs": [],
   "source": [
    "# Map Informations\n",
    "x_under_lim = 1\n",
    "x_upper_lim = 44\n",
    "y_under_lim = 1\n",
    "y_upper_lim = 15\n",
    "\n",
    "aps_positions = {'WAP1' : [4.3 , 5.0 ],\n",
    "                 'WAP2' : [8.0 , 6.0 ],\n",
    "                 'WAP3' : [16.5, 3.0 ],\n",
    "                 'WAP4' : [23.0, 3.5 ],\n",
    "                 'WAP5' : [33.0, 5.0 ],\n",
    "                 'WAP6' : [38.0, 4.3 ],\n",
    "                 'WAP7' : [39.0, 11.2],\n",
    "                 'WAP8' : [33.5, 12.0],\n",
    "                 'WAP9' : [28.5, 12.0],\n",
    "                 'WAP10': [20.0, 12.3],\n",
    "                 'WAP11': [1.5 , 11.4],\n",
    "                 'WAP12': [4.0 , 17.5],\n",
    "                 'WAP13': [13.5, 10.0],\n",
    "                 'WAP14': [17.8, 9.0 ],\n",
    "                 'WAP15': [32.3, 9.0 ]}\n",
    "\n",
    "list_aps = list(aps_positions.keys())\n",
    "\n",
    "#Constantes Log-Distance\n",
    "\n",
    "N   = 4\n",
    "d0  = 1\n",
    "PL0 = 55\n",
    "STD_DEV = 1\n",
    "TXPOWER = 0\n",
    "WALLL_LOSS = 3\n",
    "\n",
    "#PSO Infomations\n",
    "population = 20\n",
    "dimension = 2\n",
    "generation = 20\n",
    "fitness_criterion = 10e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tHfYG4kwAbD1",
   "metadata": {
    "id": "tHfYG4kwAbD1"
   },
   "source": [
    "### Comum para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78f344",
   "metadata": {
    "id": "5b78f344"
   },
   "outputs": [],
   "source": [
    "def euclidian_distance(P1, P2):\n",
    "    X1, Y1 = P1[0], P1[1]\n",
    "    X2, Y2 = P2[0], P2[1]\n",
    "    return round(math.sqrt((X2-X1)**2 + (Y2-Y1)**2),1)\n",
    "\n",
    "def toPixels(x, y):\n",
    "    return (x*100, y*100)\n",
    "\n",
    "def generateMap(particles, costs, realPosition, currentRound):\n",
    "    low_cost = 100000\n",
    "    low_position = [0,0]\n",
    "    \n",
    "    perfPixels = toPixels(realPosition[0], realPosition[1])\n",
    "    \n",
    "    plt.clf()\n",
    "    #plt.close()\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)                    \n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    img = plt.imread(\"map.png\")\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    txt = plt.text(perfPixels[0], perfPixels[1], \"✖\", weight='bold', fontsize=8, color=\"white\", verticalalignment='center', horizontalalignment='center', zorder=5)\n",
    "    txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='black')])\n",
    "\n",
    "    v_positions = []\n",
    "    groups      = {}\n",
    "    \n",
    "    for i in range(len(particles)):\n",
    "        pos = particles[i]\n",
    "        posPixels = toPixels(pos[0], pos[1])\n",
    "        label     = str(pos[0]) + str(pos[1])\n",
    "        \n",
    "        cost = costs[i]\n",
    "        \n",
    "        if cost < low_cost:\n",
    "            low_cost = cost\n",
    "            low_position = pos\n",
    "        \n",
    "        if label not in groups:\n",
    "            groups[label] = [1, posPixels[0], posPixels[1], cost]\n",
    "        else:\n",
    "            groups[label][0] += 1\n",
    "            \n",
    "        circ = Circle((posPixels[0] + np.random.normal(0, 5), posPixels[1] + np.random.normal(0, 5)), radius=10, alpha=0.5, color=\"red\", zorder=10)\n",
    "        plt.gca().add_patch(circ)\n",
    "    \n",
    "    for group in groups.values():\n",
    "        plt.annotate(\"Cost: \" + str(round(group[3], 1)), xy=(group[1]+5, group[2]-5), size=2.7, va=\"center\", ha=\"left\", xytext=(group[1] + 50, group[2] - 80), zorder=8,\n",
    "              bbox=dict(boxstyle=\"square\", facecolor=\"#ffffffcc\", edgecolor=\"#aaaaaa88\", linewidth=0.4),\n",
    "              arrowprops=dict(arrowstyle=\"-\", antialiased=True, color=\"#444444\", connectionstyle=\"arc3,rad=-0.2\", linewidth=0.15))\n",
    "        \n",
    "    #Plot Low Position\n",
    "    lowPosPixels = toPixels(low_position[0], low_position[1])\n",
    "    circ = Circle((lowPosPixels[0], lowPosPixels[1]), radius=10, color=\"#2ca05aff\", zorder=12)\n",
    "    plt.gca().add_patch(circ)\n",
    "    \n",
    "    imgFilename = \"sample-\" + str(currentRound) + \".png\"\n",
    "    plt.savefig(imgFilename, dpi=300, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907b67d",
   "metadata": {
    "id": "7907b67d"
   },
   "source": [
    "## Algoritmo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0783710",
   "metadata": {
    "id": "f0783710"
   },
   "outputs": [],
   "source": [
    "def update_velocity(particle, velocity, pbest, gbest, w_min=0.5, max=0.5, c=0.5):\n",
    "    # Initialise new velocity array\n",
    "    num_particle = len(particle)\n",
    "    new_velocity = np.array([0.0 for i in range(num_particle)])\n",
    "    \n",
    "    # Randomly generate r1, r2 and inertia weight from normal distribution\n",
    "    r1 = random.uniform(0,max)\n",
    "    r2 = random.uniform(0,max)\n",
    "    w = random.uniform(w_min,max)\n",
    "    c1 = c\n",
    "    c2 = c\n",
    "    \n",
    "    # Calculate new velocity\n",
    "    for i in range(num_particle):\n",
    "        new_velocity[i] = w*velocity[i] + c1*r1*(pbest[i]-particle[i])+c2*r2*(gbest[i]-particle[i])\n",
    "        \n",
    "    return new_velocity\n",
    "\n",
    "def update_position(particle, velocity):\n",
    "    # Move particles by adding velocity\n",
    "    new_particle = particle + velocity\n",
    "    \n",
    "    return new_particle\n",
    "\n",
    "def pso_2d(population, dimension, generation, fitness_criterion, sample, real_position):\n",
    "    # Population\n",
    "    particles = [[round(random.uniform(x_under_lim, x_upper_lim),1), round(random.uniform(y_under_lim, y_upper_lim),1)] for i in range(population)]\n",
    "    # Particle's best position\n",
    "    pbest_position = particles\n",
    "    \n",
    "    # Fitness\n",
    "    pbest_fitness = [fitness_function([p[0],p[1]], sample) for p in particles]\n",
    "    \n",
    "    # Index of the best particle\n",
    "    gbest_index = np.argmin(pbest_fitness)\n",
    "    \n",
    "    # Global best particle position\n",
    "    gbest_position = pbest_position[gbest_index]\n",
    "    \n",
    "    # Velocity (starting from 0 speed)\n",
    "    velocity = [[0.0 for j in range(dimension)] for i in range(population)]\n",
    "\n",
    "    # Loop for the number of generation\n",
    "    for t in range(generation):\n",
    "    # Stop if the average fitness value reached a predefined success criterion\n",
    "        if np.average(pbest_fitness) <= fitness_criterion:\n",
    "            break\n",
    "        else:\n",
    "            for n in range(population):\n",
    "                # Update the velocity of each particle\n",
    "                velocity[n] = update_velocity(particles[n], velocity[n], pbest_position[n], gbest_position)\n",
    "                \n",
    "                # Move the particles to new position\n",
    "                particles[n] = update_position(particles[n], velocity[n])\n",
    "        \n",
    "        # Calculate the fitness value\n",
    "        pbest_fitness = [fitness_function([p[0],p[1]], sample) for p in particles]\n",
    "        \n",
    "        # Find the index of the best particle\n",
    "        gbest_index = np.argmin(pbest_fitness)\n",
    "        \n",
    "        # Update the position of the best particle\n",
    "        gbest_position = pbest_position[gbest_index]\n",
    "        \n",
    "        ##print('Round', t+1, ', Best Position:', gbest_position, ', Cost:', pbest_fitness[gbest_index])\n",
    "        ##generateMap(particles, pbest_fitness, real_position, t)\n",
    "\n",
    "    # Print the results\n",
    "    #print('Global Best Position: ', gbest_position)\n",
    "    #print('Best Fitness Value: ', min(pbest_fitness))\n",
    "    #print('Average Particle Best Fitness Value: ', np.average(pbest_fitness))\n",
    "    #print('Number of Generation: ', t)\n",
    "    \n",
    "    return gbest_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c3a03",
   "metadata": {
    "id": "6b1c3a03"
   },
   "source": [
    "## Algoritmo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hd0sVa9jAy2v",
   "metadata": {
    "id": "hd0sVa9jAy2v"
   },
   "outputs": [],
   "source": [
    "cont = 1\n",
    "primeira=0\n",
    "rodada = 1\n",
    "\n",
    "real_position = [550, 1250]\n",
    "particulas_rodada = []\n",
    "costs_rodada = []\n",
    "\n",
    "def cost(x):\n",
    "    global primeira\n",
    "    global cont\n",
    "    global particulas_rodada\n",
    "    global costs_rodada\n",
    "    global rodada\n",
    "    \n",
    "    atualPos = [round(x[0], 1), round(x[1], 1)]\n",
    "    cost = euclidian_distance(atualPos, real_position)\n",
    "    \n",
    "    if (primeira == 0 and cont <= (population*2)) or (primeira == 1 and cont <=population):\n",
    "        cont += 1\n",
    "        particulas_rodada.append(atualPos)\n",
    "        costs_rodada.append(cost)\n",
    "    else:\n",
    "        generateMap(particulas_rodada, costs_rodada, real_position, rodada)\n",
    "        cont = 1\n",
    "        particulas_rodada = []\n",
    "        primeira = 1\n",
    "        rodada += 1\n",
    "    return cost\n",
    "\n",
    "lb = [x_under_lim, y_under_lim]\n",
    "ub = [x_upper_lim, y_upper_lim]\n",
    "\n",
    "#xopt, fopt = pso(cost, lb, ub, swarmsize=population, omega=0.5, phip=0.5, phig=0.5, maxiter=generation, minstep=1e-8, minfunc=1e-8, debug=True)\n",
    "#print('Best position: [' + str(round(xopt[0],1)) + ',' + str(round(xopt[1],1)) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f795c1",
   "metadata": {
    "id": "b7f795c1"
   },
   "source": [
    "## TESTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3f80e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jI_dHBmWr5H",
    "outputId": "ffafad08-c120-4a23-8b70-41e391609edc"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266e8c8",
   "metadata": {
    "id": "f266e8c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('db_yuri_training5_semsala42_1-todos-aps-maxValue.csv')\n",
    "#df = pd.read_csv('/content/drive/MyDrive/UFAM/Doutorado/Doutorado-Artigo3/db_yuri_training5_semsala42_1-todos-aps-maxValue.csv')\n",
    "df = df[(df[\"DEVICE\"] == '2055') | (df[\"DEVICE\"] == '121B') | (df[\"DEVICE\"] == '20B5')].reset_index(drop=True)\n",
    "\n",
    "#df_walls = pd.read_csv('/content/drive/MyDrive/UFAM/Doutorado/Doutorado-Artigo3/walls_values.csv')\n",
    "df_walls = pd.read_csv('walls_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gr7iNAwaU5bk",
   "metadata": {
    "id": "Gr7iNAwaU5bk"
   },
   "outputs": [],
   "source": [
    "def sample_dfwall_low_dist(particle_position):\n",
    "    low = 100000\n",
    "    label = ''\n",
    "\n",
    "    for i in df_walls.itertuples():\n",
    "        point_sample = [i.X, i.Y]\n",
    "        dist = euclidian_distance(particle_position, point_sample)\n",
    "\n",
    "        if dist < low:\n",
    "            label = i.LABEL\n",
    "            low = dist\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7459d42",
   "metadata": {
    "id": "c7459d42"
   },
   "outputs": [],
   "source": [
    "def attenuation():\n",
    "    u = 0\n",
    "    v = 0\n",
    "    \n",
    "    u = random.uniform(0, 1)\n",
    "    v = random.uniform(0, 1)\n",
    "    \n",
    "    normal = math.sqrt(-2.0 * math.log(u)) * math.cos(2.0 * math.pi * v)\n",
    "    return normal * STD_DEV\n",
    "\n",
    "# a linha de um dataframe (sample) vem na forma de um object e aqui transformamos em um dicionário para obter \n",
    "# apenas o número do wap e o respectivo RSSI. Isso será utilizado no cálculo da função de custo para comparar os RSSI's.\n",
    "def toDict(sample):\n",
    "    inicio_processo = time()\n",
    "    dict_sample = {}\n",
    "\n",
    "    for i in range(len(list_aps)):\n",
    "        dict_sample[list_aps[i]] = sample[list_aps[i]]\n",
    "    \n",
    "    fim_processo = time()\n",
    "    processamento = fim_processo - inicio_processo\n",
    "    print('to_dict:', round( (processamento), 1 ), 'segundos')\n",
    "    return dict_sample\n",
    "\n",
    "# Cada particula tem uma posição [x,y] e pegamos essa posição para obter as distâncias pros respectivos waps\n",
    "# e através da distância obter o RSSI entre eles. No final será retornado um dicionário com o RSSI para todos os WAPS.\n",
    "def particle_RSSI(particle_position):\n",
    "    inicio_processo = time()\n",
    "    particle_sample = {}\n",
    "\n",
    "    label = sample_dfwall_low_dist(particle_position)\n",
    "    \n",
    "    for i in range(len(list_aps)):\n",
    "        wap_position = aps_positions[list_aps[i]]\n",
    "        dist = euclidian_distance(wap_position, particle_position)\n",
    "        \n",
    "        walls_qtd = df_walls[df_walls[\"LABEL\"] == label][list_aps[i]].iloc[0]\n",
    "        \n",
    "        if dist < 0.1:\n",
    "            RSSI = -PL0\n",
    "        else:\n",
    "            distLoss = PL0 + 10 * N * math.log10(dist/d0)\n",
    "            wallLoss = walls_qtd * WALLL_LOSS\n",
    "            pathLoss = distLoss + wallLoss\n",
    "            \n",
    "            RSSI = round((TXPOWER - ( pathLoss)) + attenuation() ,0)\n",
    "    \n",
    "        if RSSI < -95: RSSI = -105\n",
    "        particle_sample[list_aps[i]] = RSSI\n",
    "    \n",
    "    fim_processo = time()\n",
    "    processamento = fim_processo - inicio_processo\n",
    "    print('particle_rssi:', round( (processamento), 1 ), 'segundos')\n",
    "    return particle_sample\n",
    "\n",
    "#RMSD entre os RSSI da particula e do sample\n",
    "def fitness_function(particle_position, sample):\n",
    "    inicio_processo = time()\n",
    "    particula = particle_RSSI(particle_position)\n",
    "    error = 0\n",
    "    \n",
    "    for i in range(len(list_aps)):\n",
    "        error += math.pow((particula[list_aps[i]] - sample[list_aps[i]]) , 2)\n",
    "    \n",
    "    error = error/len(list_aps)\n",
    "    fim_processo = time()\n",
    "    processamento = fim_processo - inicio_processo\n",
    "    print('fitness_function:', round( (processamento), 1 ), 'segundos')\n",
    "    return round(error,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5156a",
   "metadata": {
    "id": "f6b5156a"
   },
   "outputs": [],
   "source": [
    "def error_by_room(room):\n",
    "    error = []\n",
    "    room_df     = df[df['ROOM_ID'] == room]\n",
    "    room_points = room_df['LABEL'].unique()\n",
    "    \n",
    "    for point in room_points:\n",
    "        point_df = room_df[room_df['LABEL'] == point]\n",
    "        \n",
    "        for index, row in point_df.iterrows():\n",
    "            sample = toDict(row)\n",
    "            real_position = [row.X, row.Y]\n",
    "\n",
    "            estimated_position = pso_2d(population, dimension, generation, fitness_criterion, sample, real_position)\n",
    "\n",
    "            estimated_error = euclidian_distance(real_position, estimated_position)\n",
    "            #print('O erro foi de:', estimated_error, 'm')\n",
    "            \n",
    "            error.append(estimated_error)\n",
    "    \n",
    "    return_error = np.mean(error)\n",
    "    print('Sala:', room, 'Error:', return_error)\n",
    "    return round(return_error,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4121a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "8c4121a8",
    "outputId": "c79fe302-35bc-43fe-82b3-a9c062895795",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_rooms = list(df['ROOM_ID'].unique())\n",
    "\n",
    "inicio_processo = time()\n",
    "\n",
    "#subprocessos = []\n",
    "#pool = ThreadPool(processes=16)\n",
    "\n",
    "for room in tqdm(list_rooms):\n",
    "    resultado_paralelo = error_by_room(room)\n",
    "    #resultado_paralelo = pool.apply(error_by_room, (room, ))\n",
    "    subprocessos.append(resultado_paralelo)\n",
    "    break\n",
    "\n",
    "#lista_api_paralela = [result.get(timeout=120) for result in tqdm(subprocessos)]\n",
    "print('LISTA:', resultado_paralelo, 'MEDIA:', np.mean(resultado_paralelo))\n",
    "\n",
    "fim_processo = time()\n",
    "processamento_paralelo = fim_processo - inicio_processo\n",
    "print('Processamento paralelo dos id:', round( (processamento_paralelo), 1 ), 'segundos')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tHfYG4kwAbD1",
    "7907b67d",
    "6b1c3a03"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
