{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb1e4ba",
   "metadata": {
    "id": "0eb1e4ba"
   },
   "source": [
    "### Imports e Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6089fa",
   "metadata": {
    "id": "cd6089fa"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib         import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from time import sleep, time\n",
    "from multiprocessing.pool import ThreadPool, Pool\n",
    "from tqdm import tqdm\n",
    "#from pyswarm            import pso\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb143787",
   "metadata": {
    "id": "cb143787"
   },
   "outputs": [],
   "source": [
    "# Map Informations\n",
    "x_under_lim = 1\n",
    "x_upper_lim = 44\n",
    "y_under_lim = 1\n",
    "y_upper_lim = 15\n",
    "\n",
    "aps_positions = {'WAP11': [1.5 , 11.4],\n",
    "                 'WAP5' : [33.0, 5.0 ],\n",
    "                 'WAP3' : [16.5, 3.0 ],\n",
    "                 'WAP1' : [4.3 , 5.0 ],\n",
    "                 'WAP9' : [28.5, 12.0],\n",
    "                 'WAP12': [4.0 , 17.5],\n",
    "                 'WAP8' : [33.5, 12.0],\n",
    "                 'WAP10': [20.0, 12.3],\n",
    "                 'WAP6' : [38.0, 4.3 ],\n",
    "                 'WAP7' : [39.0, 11.2],\n",
    "                 'WAP4' : [23.0, 3.5 ],\n",
    "                 'WAP2' : [8.0 , 6.0 ],\n",
    "                 'WAP14': [17.8, 9.0 ],\n",
    "                 'WAP15': [32.3, 9.0 ],\n",
    "                 'WAP13': [13.5, 10.0]}\n",
    "\n",
    "list_aps = list(aps_positions.keys())\n",
    "\n",
    "#Constantes Log-Distance\n",
    "d0  = 1\n",
    "STD_DEV = 1\n",
    "TXPOWER = 0\n",
    "\n",
    "#PSO Infomations\n",
    "dimension = 2\n",
    "population = 10\n",
    "generation = 10\n",
    "fitness_criterion = 10e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tHfYG4kwAbD1",
   "metadata": {
    "id": "tHfYG4kwAbD1"
   },
   "source": [
    "### Comum para o PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78f344",
   "metadata": {
    "id": "5b78f344"
   },
   "outputs": [],
   "source": [
    "def euclidian_distance(P1, P2):\n",
    "    X1, Y1 = P1[0], P1[1]\n",
    "    X2, Y2 = P2[0], P2[1]\n",
    "    return round(math.sqrt((X2-X1)**2 + (Y2-Y1)**2),1)\n",
    "\n",
    "def toPixels(x, y):\n",
    "    return (x*100, y*100)\n",
    "\n",
    "def generateMap(particles, costs, realPosition, currentRound):\n",
    "    low_cost = 100000\n",
    "    low_position = [0,0]\n",
    "    \n",
    "    perfPixels = toPixels(realPosition[0], realPosition[1])\n",
    "    \n",
    "    plt.clf()\n",
    "    #plt.close()\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)                    \n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    img = plt.imread(\"map.png\")\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    txt = plt.text(perfPixels[0], perfPixels[1], \"✖\", weight='bold', fontsize=8, color=\"white\", verticalalignment='center', horizontalalignment='center', zorder=5)\n",
    "    txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='black')])\n",
    "\n",
    "    groups      = {}\n",
    "    \n",
    "    for i in range(len(particles)):\n",
    "        pos = particles[i]\n",
    "        posPixels = toPixels(pos[0], pos[1])\n",
    "        label     = str(pos[0]) + str(pos[1])\n",
    "        \n",
    "        cost = costs[i]\n",
    "        \n",
    "        if cost < low_cost:\n",
    "            low_cost = cost\n",
    "            low_position = pos\n",
    "        \n",
    "        if label not in groups:\n",
    "            groups[label] = [1, posPixels[0], posPixels[1], cost]\n",
    "        else:\n",
    "            groups[label][0] += 1\n",
    "            \n",
    "        circ = Circle((posPixels[0] + np.random.normal(0, 5), posPixels[1] + np.random.normal(0, 5)), radius=10, alpha=0.5, color=\"red\", zorder=10)\n",
    "        plt.gca().add_patch(circ)\n",
    "    \n",
    "    for group in groups.values():\n",
    "        plt.annotate(\"Cost: \" + str(round(group[3], 1)), xy=(group[1]+5, group[2]-5), size=2.7, va=\"center\", ha=\"left\", xytext=(group[1] + 50, group[2] - 80), zorder=8,\n",
    "              bbox=dict(boxstyle=\"square\", facecolor=\"#ffffffcc\", edgecolor=\"#aaaaaa88\", linewidth=0.4),\n",
    "              arrowprops=dict(arrowstyle=\"-\", antialiased=True, color=\"#444444\", connectionstyle=\"arc3,rad=-0.2\", linewidth=0.15))\n",
    "        \n",
    "    #Plot Low Position\n",
    "    lowPosPixels = toPixels(low_position[0], low_position[1])\n",
    "    circ = Circle((lowPosPixels[0], lowPosPixels[1]), radius=10, color=\"#2ca05aff\", zorder=12)\n",
    "    plt.gca().add_patch(circ)\n",
    "    \n",
    "    imgFilename = \"sample-\" + str(currentRound) + \".png\"\n",
    "    plt.savefig(imgFilename, dpi=300, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907b67d",
   "metadata": {
    "id": "7907b67d"
   },
   "source": [
    "## Algoritmo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73861a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = {i:[round(random.uniform(x_under_lim, x_upper_lim),1), \n",
    "                round(random.uniform(y_under_lim, y_upper_lim),1), 0, 0, 0]\n",
    "for i in range(population)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18750a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnalgo(x):\n",
    "    return [x*x,2]\n",
    "\n",
    "vet = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "[returnalgo(p)[0] for p in vet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec77b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0783710",
   "metadata": {
    "id": "f0783710"
   },
   "outputs": [],
   "source": [
    "def update_velocity(particle, velocity, pbest, gbest, w_min=0.5, max=0.5, c=0.5):\n",
    "    # Initialise new velocity array\n",
    "    num_particle = len(particle)\n",
    "    new_velocity = np.array([0.0 for i in range(num_particle)])\n",
    "    \n",
    "    # Randomly generate r1, r2 and inertia weight from normal distribution\n",
    "    r1 = random.uniform(0,max)\n",
    "    r2 = random.uniform(0,max)\n",
    "    w = random.uniform(w_min,max)\n",
    "    c1 = c\n",
    "    c2 = c\n",
    "    \n",
    "    # Calculate new velocity\n",
    "    for i in range(num_particle):\n",
    "        new_velocity[i] = round((w*velocity[i] + c1*r1*(pbest[i]-particle[i])+c2*r2*(gbest[i]-particle[i])),0)\n",
    "    \n",
    "    return new_velocity\n",
    "\n",
    "def update_position(particle, velocity):\n",
    "    # Move particles by adding velocity\n",
    "    new_particle = particle + velocity\n",
    "    \n",
    "    return new_particle\n",
    "\n",
    "def pso_2d(population, dimension, generation, fitness_criterion, real_position, row):\n",
    "    \n",
    "    seed = time()\n",
    "    random.seed(seed)\n",
    "    #print('seed:', seed)\n",
    "    \n",
    "    # Population\n",
    "    particles = [[round(random.uniform(x_under_lim, x_upper_lim),1), round(random.uniform(y_under_lim, y_upper_lim),1)] for i in range(population)]\n",
    "    \n",
    "    # Particle's best position\n",
    "    pbest_position = particles\n",
    "    \n",
    "    # Fitness\n",
    "    pbest_fitness = [fitness_function([p[0],p[1]], row) for p in particles]\n",
    "    \n",
    "    # Index of the best particle\n",
    "    gbest_index = np.argmin(pbest_fitness)\n",
    "    \n",
    "    # Global best particle position\n",
    "    gbest_position = pbest_position[gbest_index]\n",
    "    \n",
    "    # Velocity (starting from 0 speed)\n",
    "    velocity = [[0.0 for j in range(dimension)] for i in range(population)]\n",
    "\n",
    "    # Loop for the number of generation\n",
    "    for t in range(generation):\n",
    "        # Stop if the average fitness value reached a predefined success criterion\n",
    "        if np.average(pbest_fitness) <= fitness_criterion:\n",
    "            break\n",
    "        else:\n",
    "            for n in range(population):\n",
    "                # Update the velocity of each particle\n",
    "                velocity[n] = update_velocity(particles[n], velocity[n], pbest_position[n], gbest_position)\n",
    "                \n",
    "                # Move the particles to new position\n",
    "                particles[n] = update_position(particles[n], velocity[n])\n",
    "\n",
    "        # Calculate the fitness value\n",
    "        pbest_fitness = [fitness_function([p[0],p[1]], row) for p in particles]\n",
    "        \n",
    "        # Find the index of the best particle\n",
    "        gbest_index = np.argmin(pbest_fitness)\n",
    "        \n",
    "        # Update the position of the best particle\n",
    "        gbest_position = pbest_position[gbest_index]\n",
    "        \n",
    "        ##print('Round', t+1, ', Best Position:', gbest_position, ', Cost:', pbest_fitness[gbest_index])\n",
    "        ##generateMap(particles, pbest_fitness, real_position, t)\n",
    "\n",
    "    # Print the results\n",
    "    #print('Global Best Position: ', gbest_position)\n",
    "    #print('Best Fitness Value: ', min(pbest_fitness))\n",
    "    #print('Average Particle Best Fitness Value: ', np.average(pbest_fitness))\n",
    "    #print('Number of Generation: ', t)\n",
    "    \n",
    "    return gbest_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f795c1",
   "metadata": {
    "id": "b7f795c1"
   },
   "source": [
    "## TESTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3f80e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jI_dHBmWr5H",
    "outputId": "ffafad08-c120-4a23-8b70-41e391609edc"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266e8c8",
   "metadata": {
    "id": "f266e8c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('db_yuri_training5_semsala42_1-todos-aps-maxValue.csv')\n",
    "#df = pd.read_csv('/content/drive/MyDrive/UFAM/Doutorado/Doutorado-Artigo3/db_yuri_training5_semsala42_1-todos-aps-maxValue.csv')\n",
    "df = df[(df[\"DEVICE\"] == '2055') | (df[\"DEVICE\"] == '121B') | (df[\"DEVICE\"] == '20B5')].reset_index(drop=True)\n",
    "\n",
    "#df_walls = pd.read_csv('/content/drive/MyDrive/UFAM/Doutorado/Doutorado-Artigo3/walls_values.csv')\n",
    "df_walls = pd.read_csv('walls_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walls.at[41, 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 100000\n",
    "index = 10000\n",
    "\n",
    "for k,v in X.items():\n",
    "    point_sample = [v[1], v[2]]\n",
    "    dist = euclidian_distance(point_sample, particle_position)\n",
    "    \n",
    "    if dist < low:\n",
    "        low = dist\n",
    "        index = v[0]\n",
    "        \n",
    "return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa26313",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_walls.itertuples():\n",
    "    point_sample = [i.X, i.Y]\n",
    "    print('\"' +i.LABEL + '\": [' + str(i.Index)+ \",\" + str(i.X) + \",\" + str(i.Y)+'],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walls.at([0], 'WAP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7459d42",
   "metadata": {
    "id": "c7459d42"
   },
   "outputs": [],
   "source": [
    "def attenuation():\n",
    "    u = 0\n",
    "    v = 0\n",
    "    \n",
    "    u = random.uniform(0, 1)\n",
    "    v = random.uniform(0, 1)\n",
    "    \n",
    "    normal = math.sqrt(-2.0 * math.log(u)) * math.cos(2.0 * math.pi * v)\n",
    "    return normal * STD_DEV\n",
    "\n",
    "\n",
    "# Cada particula tem uma posição [x,y] e pegamos essa posição para obter as distâncias pros respectivos waps\n",
    "# e através da distância obter o RSSI entre eles. No final será retornado um dicionário com o RSSI para todos os WAPS.\n",
    "def particle_RSSI(particle_position):\n",
    "    particle_sample = {}\n",
    "\n",
    "    #label = sample_dfwall_low_dist(particle_position)\n",
    "    \n",
    "    for i in range(len(list_aps)):\n",
    "        wap_position = aps_positions[list_aps[i]]\n",
    "        dist = euclidian_distance(wap_position, particle_position)\n",
    "        \n",
    "        #walls_qtd = df_walls[df_walls[\"LABEL\"] == label][list_aps[i]].iloc[0]\n",
    "        #print(label, list_aps[i], walls_qtd)\n",
    "        walls_qtd=0\n",
    "        \n",
    "        #N   = round(random.uniform(3.5, 4.5),1)\n",
    "        #PL0 = round(random.uniform(50, 65),1)\n",
    "        #WALL_LOSS = round(random.uniform(2, 6),1)\n",
    "        \n",
    "        N = 3.5\n",
    "        PL0 = 60\n",
    "        WALL_LOSS = 3\n",
    "        \n",
    "        if dist < 0.1:\n",
    "            RSSI = -PL0\n",
    "        else:\n",
    "            distLoss = PL0 + 10 * N * math.log10(dist/d0)\n",
    "            wallLoss = walls_qtd * WALL_LOSS\n",
    "            pathLoss = distLoss + wallLoss\n",
    "            \n",
    "            #RSSI = round((TXPOWER - ( pathLoss)) + attenuation() ,0)\n",
    "            RSSI = round((TXPOWER - ( pathLoss)) ,0)\n",
    "        \n",
    "        if RSSI < -95: RSSI = -105\n",
    "        particle_sample[list_aps[i]] = RSSI\n",
    "\n",
    "    return particle_sample\n",
    "\n",
    "#RMSD entre os RSSI da particula e do sample\n",
    "def fitness_function(particle_position, row):\n",
    "    particula = particle_RSSI(particle_position)\n",
    "    error = 0\n",
    "    \n",
    "    for i in range(len(list_aps)):\n",
    "        error += math.pow((particula[list_aps[i]] - getattr(row, list_aps[i])) , 2)\n",
    "    \n",
    "    error = error\n",
    "\n",
    "    return round(error,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5156a",
   "metadata": {
    "id": "f6b5156a"
   },
   "outputs": [],
   "source": [
    "def error_by_room(room):\n",
    "    error_by_room = []\n",
    "    room_df     = df[df['ROOM_ID'] == room]\n",
    "    room_points = room_df['LABEL'].unique()\n",
    "    \n",
    "    for point in room_points:\n",
    "        point_df = room_df[room_df['LABEL'] == point]\n",
    "        \n",
    "        for row in point_df.itertuples():\n",
    "            real_position = [row.X, row.Y]\n",
    "\n",
    "            estimated_position = pso_2d(population, dimension, generation, fitness_criterion, real_position, row)\n",
    "            estimated_error = euclidian_distance(real_position, estimated_position)\n",
    "            \n",
    "            error_by_room.append(estimated_error)\n",
    "            \n",
    "    return_error = np.mean(error_by_room)\n",
    "    print('Sala:', room, 'Error:', return_error)\n",
    "    return return_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4121a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "8c4121a8",
    "outputId": "c79fe302-35bc-43fe-82b3-a9c062895795",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_rooms = list(df['ROOM_ID'].unique())\n",
    "\n",
    "inicio_processo = time()\n",
    "\n",
    "subprocessos = []\n",
    "pool = Pool(15)\n",
    "\n",
    "for room in tqdm(list_rooms):\n",
    "#for room in list_rooms:\n",
    "    #resultado_paralelo = error_by_room(room)\n",
    "    resultado_paralelo = pool.apply_async(error_by_room, (room, ))\n",
    "    subprocessos.append(resultado_paralelo)\n",
    "\n",
    "lista_api_paralela = [result.get(timeout=120) for result in tqdm(subprocessos)]\n",
    "print('\\n\\nMEDIA:', np.mean(lista_api_paralela))\n",
    "\n",
    "fim_processo = time()\n",
    "processamento_paralelo = fim_processo - inicio_processo\n",
    "print('Processamento paralelo:', round( (processamento_paralelo), 1 ), 'segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c27ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72652ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = [17.4, 12.7]\n",
    "V1 = [0.0, 0.0] \n",
    "PB1= [17.4, 12.7]\n",
    "GB1= [41.0, 4.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "593e4ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = [[17.4, 12.7], 57.0, 3.7, 2.0]\n",
    "V = [0.0, 0.0,     0.0, 0.0, 0.0]\n",
    "PB= [[17.4, 12.7], 57.0, 3.7, 2.0]\n",
    "GB= [[6.0, 24.2],  51.0, 4.5, 3.0]\n",
    "\n",
    "len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "308f3563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 * 0.0 + 0.5 * 0.07314037592334727 *( 52.0 - 52.0 )+ 0.5 * 0.05799058975917415 *( 53.0 - 52.0 )\n",
      "x= 0.028995294879587075\n",
      "   \n",
      "0.5 * 0.0 + 0.5 * 0.07314037592334727 *( 4.9 - 4.9 )+ 0.5 * 0.05799058975917415 *( 3.8 - 4.9 )\n",
      "x= -0.031894824367545795\n",
      "   \n",
      "0.5 * 0.0 + 0.5 * 0.07314037592334727 *( 2.0 - 2.0 )+ 0.5 * 0.05799058975917415 *( 5.0 - 2.0 )\n",
      "x= 0.08698588463876122\n",
      "   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.07862497,  0.02899529, -0.03189482,  0.08698588,  0.        ])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def update_velocity(particle, velocity, pbest, gbest, w_min=0.5, w_max=0.5, c=0.5):\n",
    "    # Initialise new velocity array\n",
    "    num_pos = len(particle[0])\n",
    "    num_params = len(particle)\n",
    "    \n",
    "    new_velocity = np.array([0.0 for i in range(len(particle)+1)])\n",
    "    \n",
    "    # Randomly generate r1, r2 and inertia weight from normal distribution\n",
    "    r1 = random.uniform(0,w_max)\n",
    "    r2 = random.uniform(0,w_max)\n",
    "    w = random.uniform(w_min,w_max)\n",
    "    c1 = c\n",
    "    c2 = c\n",
    "    \n",
    "    # Calculate new velocity\n",
    "    for i in range(num_pos):\n",
    "        #print(w,\"*\", velocity[i], \"+\", c1, \"*\", r1, \"*(\", pbest[0][i],\"-\",particle[0][i], \")+\", c2, \"*\", r2, \"*(\",gbest[0][i], \"-\",particle[0][i], \")\")\n",
    "        new_velocity[i] = (w*velocity[i] + c1*r1*(pbest[0][i]-particle[0][i])+c2*r2*(gbest[0][i]-particle[0][i]))\n",
    "        #print(new_velocity[i])\n",
    "        #print('   ')\n",
    "        \n",
    "    if particle[1] < gbest[1]:\n",
    "        new_velocity[2] = 2\n",
    "    elif particle[1] > gbest[1]:\n",
    "        new_velocity[2] = -2\n",
    "    else:\n",
    "        new_velocity[2] = 0\n",
    "    \n",
    "    if particle[2] < gbest[2]:\n",
    "        new_velocity[3] = 0.2\n",
    "    elif particle[2] > gbest[2]:\n",
    "        new_velocity[3] = -0.2\n",
    "    else:\n",
    "        new_velocity[3] = 0\n",
    "        \n",
    "        \n",
    "    P = 3.5\n",
    "    B = 4.0\n",
    "    # Calculate new velocity\n",
    "    for i in range(1, num_params):\n",
    "        if particle[i] < gbest[i]:\n",
    "            new_velocity[i] = 2\n",
    "        else:\n",
    "            new_velocity[i] = -2\n",
    "        \n",
    "        \n",
    "        print(w,\"*\", velocity[i+1], \"+\", c1, \"*\", r1, \"*(\", pbest[i],\"-\",particle[i], \")+\", c2, \"*\", r2, \"*(\",gbest[i], \"-\",particle[i], \")\")\n",
    "        new_velocity[i] = (w*velocity[i+1] + c1*r1*(pbest[i]-particle[i])+c2*r2*(gbest[i]-particle[i]))\n",
    "        print('x=', new_velocity[i])\n",
    "        print('   ')\n",
    "    \n",
    "    #print(new_velocity)\n",
    "    return new_velocity\n",
    "\n",
    "def update_position(particle, velocity):\n",
    "    # Move particles by adding velocity\n",
    "    new_particle = particle + velocity\n",
    "    \n",
    "    return new_particle\n",
    "\n",
    "update_velocity(P, V, PB, GB)\n",
    "#update_velocity(P1, V1, PB1, GB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7d8c83d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.8, 5.4], 52.028995294879586, 4.868105175632454, 2.0]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.028995294879587075\n",
    "b = -0.031894824367545795\n",
    "\n",
    "[[1.8, 5.4], 52.0 +a , 4.9+b, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c1d4ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P= [[1.8, 5.4], 52.0, 4.9, 2.0]\n",
    "V= [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "PB= [[1.8, 5.4], 52.0, 4.9, 2.0]\n",
    "GB=[[39.0, 3.4], 53.0, 3.8, 5.0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tHfYG4kwAbD1",
    "7907b67d",
    "6b1c3a03"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
